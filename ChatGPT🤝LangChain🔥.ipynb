{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml, openai\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import OpenAI, OpenAIChat"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT API Basics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cadentials.yaml') as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = credentials['OPENAI_API_KEY']\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = credentials['HUGGINGFACEHUB_API_TOKEN']\n",
    "openai.api_key = credentials['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<OpenAIObject chat.completion id=chatcmpl-72Gf0fYWY3kqLHrSHUEKWfJSpBj7Q at 0x246d2788db0> JSON: {\n",
       "  \"choices\": [\n",
       "    {\n",
       "      \"finish_reason\": \"stop\",\n",
       "      \"index\": 0,\n",
       "      \"message\": {\n",
       "        \"content\": \"I am an AI-powered language model assistant designed to help you with various tasks like answering questions, providing information, assisting with tasks, and more. How may I assist you today?\",\n",
       "        \"role\": \"assistant\"\n",
       "      }\n",
       "    }\n",
       "  ],\n",
       "  \"created\": 1680775054,\n",
       "  \"id\": \"chatcmpl-72Gf0fYWY3kqLHrSHUEKWfJSpBj7Q\",\n",
       "  \"model\": \"gpt-3.5-turbo-0301\",\n",
       "  \"object\": \"chat.completion\",\n",
       "  \"usage\": {\n",
       "    \"completion_tokens\": 36,\n",
       "    \"prompt_tokens\": 27,\n",
       "    \"total_tokens\": 63\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.ChatCompletion.create(\n",
    "                                model=\"gpt-3.5-turbo\",\n",
    "                                messages=[\n",
    "                                        {\"role\": \"assistant\", \"content\": \"You are a helpful assistant.\"},\n",
    "                                        {\"role\": \"user\", \"content\": \"Hello what kind of assistant are you?\"},\n",
    "                                    ]\n",
    "                                )\n",
    "response"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Mark-up Language (CML) Token System\n",
    "\n",
    "            <|im_start|>system\n",
    "            You are ChatGPT, a large language model trained by OpenAI. Answer as concisely as possible.\n",
    "            Knowledge cutoff: 2021-09-01\n",
    "            Current date: 2023-03-01<|im_end|>\n",
    "            <|im_start|>user\n",
    "            How are you<|im_end|>\n",
    "            <|im_start|>assistant\n",
    "            I am doing well!<|im_end|>\n",
    "            <|im_start|>user\n",
    "            How are you now?<|im_end|>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### system tells what kind of role the LLM should play. Key thing to note is that Token system which discribedmay changes based on the role of the LLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "            {\"role\": \"assistant\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hello what kind of assistant are you?\"},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatGPT: Hello Isuru! I am an AI language model created by OpenAI, so I don't have a name like a human. You can call me OpenAI if you like. How may I assist you today? \n",
      " 88 tokens used\n",
      "ChatGPT: As an AI language model, I don't have the capacity to compare and judge myself against other models or products. While I can certainly help you with language-related tasks, my capabilities and limitations are determined by my training dataset, programming, and other technical factors rather than marketing claims or comparisons. Nevertheless, I'd be happy to answer any questions you have or help you in any way I can. \n",
      " 202 tokens used\n",
      "ChatGPT: Yes, I can generate word embeddings using a pre-trained language model such as GPT-2 or Word2Vec. Word embeddings are numerical representations of words that are generated by analyzing large amounts of text data. They enable computers to understand the semantic relationships between words, such as synonyms, antonyms, and context. These embeddings can be used in various natural language processing (NLP) applications, such as language translation, sentiment analysis, and speech recognition. If you have more questions regarding word embeddings or NLP, feel free to ask. \n",
      " 326 tokens used\n",
      "616 tokens used in total in this conversation\n"
     ]
    }
   ],
   "source": [
    "conversation_total_tokens = 0\n",
    "\n",
    "while True:\n",
    "    message = input(\"Human: \")\n",
    "    if message=='exit':\n",
    "        print(f\"{conversation_total_tokens} tokens used in total in this conversation\")\n",
    "        break\n",
    "    if message:\n",
    "        messages.append(\n",
    "                        {\n",
    "                        \"role\": \"user\", \n",
    "                        \"content\": message\n",
    "                        },\n",
    "                        )\n",
    "        response = openai.ChatCompletion.create(\n",
    "                                                model=\"gpt-3.5-turbo\", \n",
    "                                                messages=messages\n",
    "                                                )\n",
    "    \n",
    "    reply = response.choices[0].message.content\n",
    "    total_tokens = response.usage['total_tokens']\n",
    "    conversation_total_tokens += total_tokens\n",
    "    print(f\"ChatGPT: {reply} \\n {total_tokens} tokens used\")\n",
    "    messages.append({\"role\": \"assistant\", \"content\": reply})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I'm Impressed about GPTx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT with LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix_messages = [\n",
    "                    {\n",
    "                    \"role\": \"system\", \n",
    "                    \"content\": \"You are a helpful history professor named Kate.\"\n",
    "                    }\n",
    "                  ]\n",
    "\n",
    "llm = OpenAIChat(\n",
    "                model_name='gpt-3.5-turbo', \n",
    "                temperature=0, \n",
    "                prefix_messages=prefix_messages,\n",
    "                max_tokens = 256\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Take the following question: {user_input}\n",
    "\n",
    "Answer it in an informative and intersting but conscise way for someone who is new to this topic.\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "                        template=template, \n",
    "                        input_variables=[\"user_input\"]\n",
    "                        )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example 01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Large Language Models are computer programs that use artificial intelligence to generate human-like language. They work by analyzing vast amounts of text data, such as books, articles, and websites, to learn the patterns and structures of language. This allows them to generate new text that is similar in style and tone to the original data.\\n\\nOne of the most well-known examples of a Large Language Model is GPT-3, which has been trained on a massive dataset of over 45 terabytes of text. This model can generate a wide range of text, from news articles to poetry to computer code.\\n\\nLarge Language Models are used in a variety of applications, such as chatbots, language translation, and content creation. They have the potential to revolutionize the way we interact with technology and communicate with each other. However, there are also concerns about the ethical implications of these models, such as the potential for bias and the impact on human creativity.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "user_input = \"Describe Large Language Models and how they work.\"\n",
    "\n",
    "llm_chain.run(user_input)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### example 02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GPT-3 is a language model that uses artificial intelligence to generate human-like text. It works by analyzing vast amounts of text data and learning patterns and relationships between words and phrases. This allows it to generate coherent and contextually appropriate responses to prompts or questions. Essentially, it's like a very advanced version of predictive text on your phone, but on a much larger scale. It has the potential to revolutionize the way we interact with technology and communicate with each other.\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "user_input = \"Describe the GPT-3 model and how it works.\"\n",
    "\n",
    "llm_chain.run(user_input)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
