{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml, openai\n",
    "from langchain import OpenAI\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Dict, Any\n",
    "from langchain.llms import HuggingFaceHub\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.prompts.prompt import PromptTemplate\n",
    "from langchain.chains.conversation.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cadentials.yaml') as f:\n",
    "    credentials = yaml.load(f, Loader=yaml.FullLoader)\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = credentials['OPENAI_API_KEY']\n",
    "os.environ['HUGGINGFACEHUB_API_TOKEN'] = credentials['HUGGINGFACEHUB_API_TOKEN']\n",
    "openai.api_key = credentials['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Legion\\AppData\\Roaming\\Python\\Python38\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "flan_ul2 = HuggingFaceHub(\n",
    "                        repo_id=\"google/flan-ul2\", \n",
    "                        model_kwargs={\n",
    "                                    \"temperature\":0.1,\n",
    "                                    \"max_new_tokens\":256\n",
    "                                    }\n",
    "                        )\n",
    "\n",
    "flan_t5 = HuggingFaceHub(\n",
    "                        repo_id=\"google/flan-t5-xl\",\n",
    "                        model_kwargs={\"temperature\":0 }\n",
    "                        )\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "                                llm=flan_ul2, \n",
    "                                verbose=True, \n",
    "                                memory=memory\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there! I am Isuru\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Hi, I am Isuru. What can I help you with?'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there! I am Isuru\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! I am Isuru\n",
      "AI: Hi, I am Isuru. What can I help you with?\n",
      "Human: I am very lazy now to go to the gym. I am thinking to skip it today. Help me to decide.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I can help you with that. I can check your calendar and see if you have any appointments today.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"I am very lazy now to go to the gym. I am thinking to skip it today. Help me to decide.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there! I am Isuru\n",
      "AI: Hi, I am Isuru. What can I help you with?\n",
      "Human: I am very lazy now to go to the gym. I am thinking to skip it today. Help me to decide.\n",
      "AI: I can help you with that. I can check your calendar and see if you have any appointments today.\n",
      "Human: Thanks for your help. I will go to the gym today.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'I am glad to help.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Thanks for your help. I will go to the gym today.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch113",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
